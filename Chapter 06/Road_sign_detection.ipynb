{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ddec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('GTSRB'):\n",
    "    !pip install -U -q torch_snippets\n",
    "    !wget -qq https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
    "    !wget -qq https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n",
    "    !unzip -qq GTSRB_Final_Training_Images.zip\n",
    "    !unzip -qq GTSRB_Final_Test_Images.zip\n",
    "    !wget https://raw.githubusercontent.com/georgesung/traffic_sign_classification_german/master/signnames.csv\n",
    "    !rm GTSRB_Final_Training_Images.zip GTSRB_Final_Test_Images.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981dd56",
   "metadata": {},
   "source": [
    "### Without Batch normalization and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "classIds = pd.read_csv('signnames.csv')\n",
    "classIds.set_index('ClassId', inplace=True)\n",
    "classIds = classIds.to_dict()['SignName']\n",
    "classIds = {f'{k:05d}':v for k,v in classIds.items()}\n",
    "id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())}\n",
    "\n",
    "from torchvision import transforms as T\n",
    "classIds = pd.read_csv('signnames.csv')\n",
    "classIds.set_index('ClassId', inplace=True)\n",
    "classIds = classIds.to_dict()['SignName']\n",
    "classIds = {f'{k:05d}':v for k,v in classIds.items()}\n",
    "id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())}\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "trn_tfms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    # T.ColorJitter(brightness=(0.8,1.2), \n",
    "    # contrast=(0.8,1.2), \n",
    "    # saturation=(0.8,1.2), \n",
    "    # hue=0.25),\n",
    "    # T.RandomAffine(5, translate=(0.01,0.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class GTSRB(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, files, transform=None):\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "        logger.info(len(self))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        fpath = self.files[ix]\n",
    "        clss = fname(parent(fpath))\n",
    "        img = read(fpath, 1)\n",
    "        return img, classIds[clss]\n",
    "\n",
    "    def choose(self):\n",
    "        return self[randint(len(self))]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        imgs, classes = list(zip(*batch))\n",
    "        if self.transform:\n",
    "            imgs = [self.transform(img)[None] for img in imgs]\n",
    "        classes = [torch.tensor([id2int[clss]]) for clss in classes]\n",
    "        imgs, classes = [torch.cat(i).to(device) for i in [imgs, classes]]\n",
    "        return imgs, classes\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "all_files = Glob('GTSRB/Final_Training/Images/*/*.ppm')\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(all_files)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trn_files, val_files = train_test_split(all_files, random_state=1)\n",
    "\n",
    "trn_ds = GTSRB(trn_files, transform=trn_tfms)\n",
    "val_ds = GTSRB(val_files, transform=val_tfms)\n",
    "trn_dl = DataLoader(trn_ds, 32, shuffle=True, collate_fn=trn_ds.collate_fn)\n",
    "val_dl = DataLoader(val_ds, 32, shuffle=False, collate_fn=val_ds.collate_fn)\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "def convBlock(ni, no):\n",
    "    return nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Conv2d(ni, no, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        #nn.BatchNorm2d(no),\n",
    "        nn.MaxPool2d(2),\n",
    "    )\n",
    "    \n",
    "class SignClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            convBlock(3, 64),\n",
    "            convBlock(64, 64),\n",
    "            convBlock(64, 128),\n",
    "            convBlock(128, 64),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, len(id2int))\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_metrics(self, preds, targets):\n",
    "        ce_loss = self.loss_fn(preds, targets)\n",
    "        acc = (torch.max(preds, 1)[1] == targets).float().mean()\n",
    "        return ce_loss, acc\n",
    "def train_batch(model, data, optimizer, criterion):\n",
    "    ims, labels = data\n",
    "    _preds = model(ims)\n",
    "    optimizer.zero_grad()\n",
    "    loss, acc = criterion(_preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), acc.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_batch(model, data, criterion):\n",
    "    ims, labels = data\n",
    "    _preds = model(ims)\n",
    "    loss, acc = criterion(_preds, labels)\n",
    "    return loss.item(), acc.item()\n",
    "model = SignClassifier().to(device)\n",
    "criterion = model.compute_metrics\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 40\n",
    "\n",
    "log = Report(n_epochs)\n",
    "for ex in range(n_epochs):\n",
    "    N = len(trn_dl)\n",
    "    for bx, data in enumerate(trn_dl):\n",
    "        loss, acc = train_batch(model, data, optimizer, criterion)\n",
    "        log.record(ex+(bx+1)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n",
    "\n",
    "    N = len(val_dl)\n",
    "    for bx, data in enumerate(val_dl):\n",
    "        loss, acc = validate_batch(model, data, criterion)\n",
    "        log.record(ex+(bx+1)/N, val_loss=loss, val_acc=acc, end='\\r')\n",
    "        \n",
    "    log.report_avgs(ex+1)\n",
    "    if ex == 10: optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "log.plot_epochs()\n",
    "dumpdill(log, 'no-aug-no-bn.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9c6cb",
   "metadata": {},
   "source": [
    "### With Batch normalization but without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba041832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "classIds = pd.read_csv('signnames.csv')\n",
    "classIds.set_index('ClassId', inplace=True)\n",
    "classIds = classIds.to_dict()['SignName']\n",
    "classIds = {f'{k:05d}':v for k,v in classIds.items()}\n",
    "id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())}\n",
    "\n",
    "from torchvision import transforms as T\n",
    "classIds = pd.read_csv('signnames.csv')\n",
    "classIds.set_index('ClassId', inplace=True)\n",
    "classIds = classIds.to_dict()['SignName']\n",
    "classIds = {f'{k:05d}':v for k,v in classIds.items()}\n",
    "id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())}\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "trn_tfms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    # T.ColorJitter(brightness=(0.8,1.2), \n",
    "    # contrast=(0.8,1.2), \n",
    "    # saturation=(0.8,1.2), \n",
    "    # hue=0.25),\n",
    "    # T.RandomAffine(5, translate=(0.01,0.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class GTSRB(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, files, transform=None):\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "        logger.info(len(self))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        fpath = self.files[ix]\n",
    "        clss = fname(parent(fpath))\n",
    "        img = read(fpath, 1)\n",
    "        return img, classIds[clss]\n",
    "\n",
    "    def choose(self):\n",
    "        return self[randint(len(self))]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        imgs, classes = list(zip(*batch))\n",
    "        if self.transform:\n",
    "            imgs = [self.transform(img)[None] for img in imgs]\n",
    "        classes = [torch.tensor([id2int[clss]]) for clss in classes]\n",
    "        imgs, classes = [torch.cat(i).to(device) for i in [imgs, classes]]\n",
    "        return imgs, classes\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "all_files = Glob('GTSRB/Final_Training/Images/*/*.ppm')\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(all_files)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trn_files, val_files = train_test_split(all_files, random_state=1)\n",
    "\n",
    "trn_ds = GTSRB(trn_files, transform=trn_tfms)\n",
    "val_ds = GTSRB(val_files, transform=val_tfms)\n",
    "trn_dl = DataLoader(trn_ds, 32, shuffle=True, collate_fn=trn_ds.collate_fn)\n",
    "val_dl = DataLoader(val_ds, 32, shuffle=False, collate_fn=val_ds.collate_fn)\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "def convBlock(ni, no):\n",
    "    return nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Conv2d(ni, no, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm2d(no),\n",
    "        nn.MaxPool2d(2),\n",
    "    )\n",
    "    \n",
    "class SignClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            convBlock(3, 64),\n",
    "            convBlock(64, 64),\n",
    "            convBlock(64, 128),\n",
    "            convBlock(128, 64),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, len(id2int))\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_metrics(self, preds, targets):\n",
    "        ce_loss = self.loss_fn(preds, targets)\n",
    "        acc = (torch.max(preds, 1)[1] == targets).float().mean()\n",
    "        return ce_loss, acc\n",
    "def train_batch(model, data, optimizer, criterion):\n",
    "    ims, labels = data\n",
    "    _preds = model(ims)\n",
    "    optimizer.zero_grad()\n",
    "    loss, acc = criterion(_preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), acc.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_batch(model, data, criterion):\n",
    "    ims, labels = data\n",
    "    _preds = model(ims)\n",
    "    loss, acc = criterion(_preds, labels)\n",
    "    return loss.item(), acc.item()\n",
    "model = SignClassifier().to(device)\n",
    "criterion = model.compute_metrics\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 40\n",
    "\n",
    "log = Report(n_epochs)\n",
    "for ex in range(n_epochs):\n",
    "    N = len(trn_dl)\n",
    "    for bx, data in enumerate(trn_dl):\n",
    "        loss, acc = train_batch(model, data, optimizer, criterion)\n",
    "        log.record(ex+(bx+1)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n",
    "\n",
    "    N = len(val_dl)\n",
    "    for bx, data in enumerate(val_dl):\n",
    "        loss, acc = validate_batch(model, data, criterion)\n",
    "        log.record(ex+(bx+1)/N, val_loss=loss, val_acc=acc, end='\\r')\n",
    "        \n",
    "    log.report_avgs(ex+1)\n",
    "    if ex == 10: optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "log.plot_epochs()\n",
    "dumpdill(log, 'no-aug-yes-bn.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efffb96",
   "metadata": {},
   "source": [
    "### With Batch normalization and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "classIds = pd.read_csv('signnames.csv')\n",
    "classIds.set_index('ClassId', inplace=True)\n",
    "classIds = classIds.to_dict()['SignName']\n",
    "classIds = {f'{k:05d}':v for k,v in classIds.items()}\n",
    "id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())}\n",
    "\n",
    "from torchvision import transforms as T\n",
    "classIds = pd.read_csv('signnames.csv')\n",
    "classIds.set_index('ClassId', inplace=True)\n",
    "classIds = classIds.to_dict()['SignName']\n",
    "classIds = {f'{k:05d}':v for k,v in classIds.items()}\n",
    "id2int = {v:ix for ix,(k,v) in enumerate(classIds.items())}\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "trn_tfms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    T.ColorJitter(brightness=(0.8,1.2), \n",
    "    contrast=(0.8,1.2), \n",
    "    saturation=(0.8,1.2), \n",
    "    hue=0.25),\n",
    "    T.RandomAffine(5, translate=(0.01,0.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(32),\n",
    "    T.CenterCrop(32),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class GTSRB(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, files, transform=None):\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "        logger.info(len(self))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        fpath = self.files[ix]\n",
    "        clss = fname(parent(fpath))\n",
    "        img = read(fpath, 1)\n",
    "        return img, classIds[clss]\n",
    "\n",
    "    def choose(self):\n",
    "        return self[randint(len(self))]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        imgs, classes = list(zip(*batch))\n",
    "        if self.transform:\n",
    "            imgs = [self.transform(img)[None] for img in imgs]\n",
    "        classes = [torch.tensor([id2int[clss]]) for clss in classes]\n",
    "        imgs, classes = [torch.cat(i).to(device) for i in [imgs, classes]]\n",
    "        return imgs, classes\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "all_files = Glob('GTSRB/Final_Training/Images/*/*.ppm')\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(all_files)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trn_files, val_files = train_test_split(all_files, random_state=1)\n",
    "\n",
    "trn_ds = GTSRB(trn_files, transform=trn_tfms)\n",
    "val_ds = GTSRB(val_files, transform=val_tfms)\n",
    "trn_dl = DataLoader(trn_ds, 32, shuffle=True, collate_fn=trn_ds.collate_fn)\n",
    "val_dl = DataLoader(val_ds, 32, shuffle=False, collate_fn=val_ds.collate_fn)\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "def convBlock(ni, no):\n",
    "    return nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Conv2d(ni, no, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm2d(no),\n",
    "        nn.MaxPool2d(2),\n",
    "    )\n",
    "    \n",
    "class SignClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            convBlock(3, 64),\n",
    "            convBlock(64, 64),\n",
    "            convBlock(64, 128),\n",
    "            convBlock(128, 64),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, len(id2int))\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_metrics(self, preds, targets):\n",
    "        ce_loss = self.loss_fn(preds, targets)\n",
    "        acc = (torch.max(preds, 1)[1] == targets).float().mean()\n",
    "        return ce_loss, acc\n",
    "def train_batch(model, data, optimizer, criterion):\n",
    "    ims, labels = data\n",
    "    _preds = model(ims)\n",
    "    optimizer.zero_grad()\n",
    "    loss, acc = criterion(_preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), acc.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_batch(model, data, criterion):\n",
    "    ims, labels = data\n",
    "    _preds = model(ims)\n",
    "    loss, acc = criterion(_preds, labels)\n",
    "    return loss.item(), acc.item()\n",
    "model = SignClassifier().to(device)\n",
    "criterion = model.compute_metrics\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 40\n",
    "\n",
    "log = Report(n_epochs)\n",
    "for ex in range(n_epochs):\n",
    "    N = len(trn_dl)\n",
    "    for bx, data in enumerate(trn_dl):\n",
    "        loss, acc = train_batch(model, data, optimizer, criterion)\n",
    "        log.record(ex+(bx+1)/N, trn_loss=loss, trn_acc=acc, end='\\r')\n",
    "\n",
    "    N = len(val_dl)\n",
    "    for bx, data in enumerate(val_dl):\n",
    "        loss, acc = validate_batch(model, data, criterion)\n",
    "        log.record(ex+(bx+1)/N, val_loss=loss, val_acc=acc, end='\\r')\n",
    "        \n",
    "    log.report_avgs(ex+1)\n",
    "    if ex == 10: optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "log.plot_epochs()\n",
    "dumpdill(log, '40-yes-aug-yes-bn.log')\n",
    "from google.colab import files\n",
    "files.download('40-yes-aug-yes-bn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in Glob('*.log'):\n",
    "    log = loaddill(f)\n",
    "    print()\n",
    "    log.report_avgs(20)\n",
    "    log.plot_epochs(['trn_acc', 'val_acc'], title=f.replace(',','\\n').replace('.log',''))\n",
    "    print()\n",
    "    line()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2d85c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
